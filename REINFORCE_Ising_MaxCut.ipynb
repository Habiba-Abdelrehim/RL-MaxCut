{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqDVXFTilQhT"
      },
      "source": [
        "# **Deterministic Policy Gradient for RL-Based MaxCut on Sparse Ising Graphs**\n",
        "\n",
        "### Habiba Abdelrehim\n",
        "### Sarah Ameur\n",
        "### Fadi Younes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LyoD2lW2OFr"
      },
      "source": [
        "README:\n",
        "\n",
        "First, it is necessary you run cell \"1. Libraries\" to import all necessary libraries.\n",
        "\n",
        "Then, it is necessary you run cell \"2. Downloading the data for table 1 & 2\" to import the datasets for all the graph to be tested in various experiments.\n",
        "\n",
        "After that, you can choose what cell to run depending on what experiment you want to run.\n",
        "\n",
        "If you want to test our implementation of the Deterministic-Reinforce algorithm, it is necessary you run cells under \"3. Deterministic Reinforce\". But first, modify the line \"file_name = ...\" to input on which graph you want to test the algorithm.\n",
        "\n",
        "If you want to test our implementation of the Metropolis algorithm, it is necessary you run cells under \"4. Benchmark against Metropolis\".\n",
        "\n",
        "If you want to test our implementation of the pure greedy local search Algorithm, it is necessary you run cells under \"5. Benchmark against Pure greedy local search\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WFyYkj1-kVY"
      },
      "source": [
        "#**1. Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eJFtmQ8Y0lf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from urllib import request\n",
        "import scipy.sparse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import gc\n",
        "import math\n",
        "from itertools import product\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "from google.colab import runtime\n",
        "import networkx as nx\n",
        "import time\n",
        "import scipy.sparse as sp\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # choose GPU if present, else CPU\n",
        "print(\"Running on:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTMvPFp5jLUw"
      },
      "source": [
        "#**2. Downloading the data for table 1 & 2**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goxh1bzL_iAJ"
      },
      "outputs": [],
      "source": [
        "# Code to download all the graphs datasets to do the experiments, you just have to run this cell to download all the dataset, no need to get them from the websites\n",
        "\n",
        "dataFile_id = \"1d8i-Ylt1TjoejHz3rVw8Omm7OgJEohFA\"\n",
        "dest_folder='./'\n",
        "URL = \"https://docs.google.com/uc?export=download\"\n",
        "session = requests.Session()\n",
        "response = session.get(URL, params={'id': dataFile_id}, stream=True)\n",
        "\n",
        "\n",
        "with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
        "    os.makedirs(dest_folder, exist_ok=True)\n",
        "    z.extractall(dest_folder)\n",
        "\n",
        "print(f\"All data files extracted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk7pTZin2qmw"
      },
      "source": [
        "##**Optsicom graphs (Table 1)**\n",
        "\n",
        "* The Optsicom graphs are sparse random-generated graphs developped as part of the Optsicom project. The data designed for MaxCut problems can be downloaded from: https://grafo.etsii.urjc.es/optsicom/maxcut.html, under \"Set2\".\n",
        "* 1. Go to Optsicom website. > 2. Left tab: Optimization Problems. > 3. Under \"Set2\": Download the data. > 4. Upload it on your local environment in Colab. Make sure to give files the same names, example: \"g54100.mc\". The correct files are the first 10 of the list.\n",
        "\n",
        "##**Gset graphs (Table 2)**\n",
        "\n",
        "* The *Gset* dataset contains graphs with sparse random structure. It can be found here: https://web.stanford.edu/~yyye/yyye/Gset/.\n",
        "* To understand structure of the Gset data, check out: https://medium.com/toshiba-sbm/benchmarking-the-max-cut-problem-on-the-simulated-bifurcation-machine-e26e1127c0b0.\n",
        "  * The data is space-separated.\n",
        "  * The first row of every file contains the number of vertices followed by the number of edges.\n",
        "  * Each row after that contains a node $i$, followed by a node $j$, and finally the weight $w_{ij}$ of the edge connecting nodes $i$ and $j$.\n",
        "* The graphs G14, G15, G22, G49, G50, G55, and G70 have edges with uniform weights $w=1$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnIPdjy7z622"
      },
      "source": [
        "#**3. Deterministic Reinforce**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDT27ikc_zpr"
      },
      "source": [
        "In this section, we attempt to reproduce the results from the paper \"Reinforcement Learning for Ising Model\", by Lu and Liu https://ml4physicalsciences.github.io/2023/files/NeurIPS_ML4PS_2023_248.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMPXTyFzqtJ1"
      },
      "source": [
        "* The input and output layers have $n$ neurons to represent each spin/node of the graph.\n",
        "* The current spin state $s_t=(\\sigma_{1, t}, \\sigma_{2, t}, ..., \\sigma_{n^2, t})$ is fed to the input layer. After one forward pass, the next state $s_{t+1}$ is produced at the output layer in the form of probabilities to flip each spin: $p_{\\theta}(\\sigma_i | s_t)$.\n",
        "* In alignment with deterministic policy update, the next state $s_{t+1}$ is selected based on a fixed threshold of probability 0.5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9mJ2LYmsSFm"
      },
      "source": [
        "$∇_{\\theta}J(\\theta) = \\frac{1}{N}\\Sigma_{i=1}^N \\Sigma_{t=0}^{T}\n",
        "  R_t^i∇_\\theta \\log \\pi_\\theta(s_{t+1}|s_t)$\n",
        "   **(9)**\n",
        "\n",
        "Helper functions help break down Eq. 9 of paper into manageable chunks:\n",
        "* The cumulative returns $R_t^i$ are calculated using the `hamilton` helper function.\n",
        "* The log-probability of transition $\\log \\pi_{\\theta}(s_{t+1} | s_t)$ is calculated using the `log_prob` helper function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5GMwW0c0fZU"
      },
      "source": [
        "* Nodes connected by an edge are spin-spin neighbors.\n",
        "  * Nodes have spin values $\\sigma_i\\in\\{-1,+1\\}$.\n",
        "  * Coupling is uniform, i.e., $J_{ij} = 1$. This means the weights of every edge is $w_{ij}=1$.\n",
        "  * Connected nodes $(i,j)\\in E$ contribute to the Hamiltonian depending on their relative spins:\n",
        "    * If $\\sigma_i \\sigma_j > 0$, the pair increases the Hamiltonian.\n",
        "    * If $\\sigma_i \\sigma_j < 0$, the pair lowers the Hamiltonian.\n",
        "  * Nodes that aren't connected don't interact, therefore don't contribute to the Hamiltonian."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jxm8bVF_CJDf"
      },
      "source": [
        "##**Implementation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s19ozUmDBZ9_"
      },
      "outputs": [],
      "source": [
        "#Choose which graph to use by commenting and uncommenting and changing the string for file_name\n",
        "\n",
        "# For table 1\n",
        "file_name = './g54100.mc' # or g54200, g54300...\n",
        "\n",
        "# For table 2\n",
        "#file_name = './G14.mc' # or G15, G22...\n",
        "\n",
        "# Deterministic‑REINFORCE algorithm\n",
        "\n",
        "# Input hyperparametes to test in their respective list\n",
        "tries_values        = [1]          # LS moves attempted\n",
        "T_values            = [10.0]         # Metropolis temperature\n",
        "steps_values        = [30]                  # Metropolis burn‑in steps\n",
        "epochs_values       = [25]               # training epochs\n",
        "batch_values        = [4]                 # parallel chains\n",
        "traj_values         = [5]                  # trajectory length\n",
        "lr_values           = [9e-6]            # learning rate\n",
        "flips_ratio_values  = [0.01]            # LS flips as a fraction of n\n",
        "\n",
        "grid = product(tries_values,\n",
        "               T_values,\n",
        "               steps_values,\n",
        "               epochs_values,\n",
        "               batch_values,\n",
        "               traj_values,\n",
        "               lr_values,\n",
        "               flips_ratio_values)\n",
        "\n",
        "for (tries, T, steps, epochs, batch, traj, lr, flips_ratio) in grid:\n",
        "    # Unpack the tuple into the value of variables\n",
        "    tries_value        = tries\n",
        "    T_value            = T\n",
        "    steps_value        = steps\n",
        "    epochs_value       = epochs\n",
        "    batch_value        = batch\n",
        "    traj_value         = traj\n",
        "    lr_value           = lr\n",
        "    flips_ratio_value  = flips_ratio\n",
        "\n",
        "    # Convert dense NumPy adjacency to sparse PyTorch tensor on GPU\n",
        "    def to_sparse(adj):\n",
        "        sparse_mtx = scipy.sparse.coo_matrix(adj)     # build SciPy sparse matrix\n",
        "        idx = torch.tensor([sparse_mtx.row, sparse_mtx.col], device=device)   # edge indices as 2*|E| tensor\n",
        "        val = torch.tensor(sparse_mtx.data, dtype=torch.float32, device=device)  # edge weights\n",
        "        return torch.sparse_coo_tensor(idx, val, sparse_mtx.shape).coalesce()    # create & coalesce sparse tensor\n",
        "\n",
        "\n",
        "    # Read .mc graph into dense NumPy adjacency\n",
        "    def parse_mc(fname):\n",
        "        with open(fname) as f:\n",
        "            n, _ = map(int, f.readline().split())   # first line: nbr of nodes, dummy value\n",
        "            A = np.zeros((n, n), dtype=np.float32)    # allocate n*n zeros matrix\n",
        "            for line in f:        # remaining lines: u v w\n",
        "                u, v, w = map(int, line.split())\n",
        "                A[u - 1, v - 1] = w      # 1‑indexed file so 0‑indexed Python\n",
        "                A[v - 1, u - 1] = w      # undirected graph then symmetric\n",
        "        return A\n",
        "\n",
        "    # Compute Ising Hamiltonian H(s)= 1/4 sum of A_ij sigma_i * sigma_j for a batch of spin vectors\n",
        "    def hamilton(spins, A):\n",
        "        if spins.dim() == 1:\n",
        "            spins = spins.unsqueeze(0)     # promote 1D vector → batch size 1\n",
        "        A = A.coalesce()    # ensure indices / values are compact\n",
        "        idx, val = A.indices(), A.values()   # edge list & weights\n",
        "        prod = spins[:, idx[0]] * spins[:, idx[1]] * val   # element‑wise sigma_i sigma_j * w_ij\n",
        "        return 0.5 * prod.sum(dim=1)  # returns 1D tensor of size B\n",
        "\n",
        "\n",
        "    # Compute Max‑Cut value = 1/4 sum of A_ij(1−sigma_i*sigma_j) for a batch\n",
        "    @torch.no_grad()\n",
        "    def cutsize(spins, A):\n",
        "        if spins.dim() == 1:\n",
        "            spins = spins.unsqueeze(0)\n",
        "        A = A.coalesce()\n",
        "        idx, val = A.indices(), A.values()\n",
        "        prod = (1.0 - spins[:, idx[0]] * spins[:, idx[1]]) * val    # (1−sigma_i*sigma_j) * w_ij\n",
        "        return 0.25 * prod.sum(dim=1)\n",
        "\n",
        "\n",
        "    # Batch greedy flip local search: random‑flip bits; accept whole move if H decreases. Repeat 'tries' number of times.\n",
        "    @torch.no_grad()\n",
        "    def local_search(spins, A, *, flips=100, tries=tries_value):\n",
        "        B, n = spins.shape       # B=batch size, n=#nodes\n",
        "        best = spins.clone()      # best known states so far\n",
        "        best_H = hamilton(best, A)  # their energies\n",
        "        A = A.coalesce()\n",
        "        idxE, valE = A.indices(), A.values()   # local vars for speed\n",
        "        for _ in range(tries):\n",
        "            trial = best.clone()   # start from current best\n",
        "            flip = torch.randint(0, n, (B, flips), device=device)   # random indices per batch row\n",
        "            rows = torch.arange(B, device=device).unsqueeze(1).expand(-1, flips).reshape(-1)  # row ids\n",
        "            trial[rows, flip.reshape(-1)] *= -1  # flip chosen spins\n",
        "            Ht = hamilton(trial, A)   # energy after flip\n",
        "            mask = Ht < best_H    # improvement mask\n",
        "            best[mask] = trial[mask]  # accept better configs\n",
        "            best_H[mask] = Ht[mask]   # update best energies\n",
        "        return best       # return locally improved spins\n",
        "\n",
        "    # Metropolis–Hastings burn‑in: single‑spin updates per batch row. Accept downhill moves or uphill with Boltzmann probability.\n",
        "    @torch.no_grad()\n",
        "    def metropolis(spins, A, *, T=T_value, steps=steps_value):\n",
        "        B, n = spins.shape\n",
        "        A = A.coalesce()\n",
        "        rows, cols = A.indices() # source/target node indices per edge\n",
        "        vals = A.values()\n",
        "        for _ in range(steps):\n",
        "            k = torch.randint(0, n, (B,), device=device)    # pick a spin index per batch element\n",
        "            old = spins[torch.arange(B, device=device), k]      # current spin value (+1/-1)\n",
        "            dE = torch.zeros(B, device=device)      # delta_E for each batch element\n",
        "            for b in range(B):     # loop over batch rows (small B)\n",
        "                mask = rows == k[b]      # edges incident to spin k[b]\n",
        "                dE[b] = -2.0 * old[b] * (spins[b, cols[mask]] * vals[mask]).sum()  # delta_E formula\n",
        "            acc = (dE <= 0) | (torch.rand(B, device=device) < torch.exp(-dE / T))  # accept moves ?\n",
        "            spins[acc, k[acc]] *= -1    # flip accepted spins\n",
        "        return spins\n",
        "\n",
        "    # Simple 3‑layer MLP; outputs P(sigma=-1) for each node.\n",
        "    class PolicyNet(nn.Module):\n",
        "        def __init__(self, n):\n",
        "            super().__init__()\n",
        "            self.net = nn.Sequential(\n",
        "                nn.Linear(n, n), nn.ReLU(),  # hidden layer 1\n",
        "                nn.Linear(n, n), nn.ReLU(),  # hidden layer 2\n",
        "                nn.Linear(n, n), nn.Sigmoid()   # outputs in (0,1)\n",
        "            )\n",
        "        def forward(self, x):\n",
        "            return self.net(x)    # forward pass: B*N then B*N probabilities\n",
        "\n",
        "    # Log‑likelihood of deterministic choice (threshold 0.5) given probabilities p\n",
        "    def log_prob(p, spins):\n",
        "        eps = 1e-9\n",
        "        return torch.where(spins == -1, (p + eps).log(), (1 - p + eps).log()).sum(dim=1)\n",
        "\n",
        "\n",
        "    # Main deterministic‑REINFORCE training loop. A: sparse adjacency; returns (history of H, best cut found).\n",
        "    def train(A, epochs=epochs_value, batch=batch_value, traj=traj_value, lr=lr_value, flips_ratio=flips_ratio_value):\n",
        "        n = A.shape[0]       # number of nodes\n",
        "        net = PolicyNet(n).to(device)    # policy network\n",
        "        opt = optim.Adam(net.parameters(), lr=lr)     # Adam optimiser\n",
        "        sched = optim.lr_scheduler.CosineAnnealingLR(opt, epochs) # cosine LR schedule\n",
        "\n",
        "        best_cut, hist = -math.inf, []   # track best cut & H history\n",
        "        for ep in range(1, epochs + 1):  # training epochs\n",
        "            s = 2 * torch.randint(0, 2, (batch, n), device=device) - 1  # random +/-1 spins\n",
        "            s = metropolis(s, A)  # burn‑in via Metropolis\n",
        "            log_pi, rewards = [], []  # per‑step logs & rewards\n",
        "\n",
        "            for _ in range(traj):     # trajectory of length T\n",
        "                p = net(s.float())   # forward pass → probabilities\n",
        "                nxt = torch.where(p > 0.5, -torch.ones_like(p), torch.ones_like(p)).detach()  # deterministic action\n",
        "                s_hat = local_search(s, A, flips=int(flips_ratio * n), tries=tries_value)  # LS on current\n",
        "                nxt_hat = local_search(nxt, A, flips=int(flips_ratio * n), tries=tries_value)  # LS on next\n",
        "                r = hamilton(s_hat, A) - hamilton(nxt_hat, A)     # reward = energy decrease\n",
        "                log_pi.append(log_prob(p, nxt))  # store log‑prob\n",
        "                rewards.append(r)  # store reward\n",
        "                s = nxt_hat     # advance to next state\n",
        "\n",
        "            R = torch.flip(torch.cumsum(torch.flip(torch.stack(rewards), [0]), 0), [0])  # discounted‑sum\n",
        "            base = R.mean(dim=1, keepdim=True)    # baseline for variance reduction\n",
        "            adv = (R - base).detach()  # advantage (no grad)\n",
        "            loss = -(adv * torch.stack(log_pi)).sum() / batch    # REINFORCE loss (minimise −J)\n",
        "            opt.zero_grad(set_to_none=True)   # clear gradients\n",
        "            loss.backward()  # backprop\n",
        "            opt.step()  # optimiser step\n",
        "            sched.step()   # LR scheduler step\n",
        "\n",
        "            cur_H = hamilton(s, A).mean().item()  # mean energy of final batch state\n",
        "            hist.append(cur_H)    # add to history\n",
        "\n",
        "            # evaluation every 25 epochs\n",
        "            if ep % 25 == 0 or ep == epochs:\n",
        "                with torch.no_grad():\n",
        "                    test = 2 * torch.randint(0, 2, (batch, n), device=device) - 1\n",
        "                    test = metropolis(test, A) # burn‑in\n",
        "                    p = net(test.float())\n",
        "                    nxt = torch.where(p > 0.5, -torch.ones_like(p), torch.ones_like(p))\n",
        "                    nxt = local_search(nxt, A, flips=int(flips_ratio * n), tries=500)  # strong LS\n",
        "                    val = cutsize(nxt, A).max().item()  # best cut in batch\n",
        "                    best_cut = max(best_cut, val)      # update global best\n",
        "                print(f\"[{ep:4d}/{epochs}]  ⟨H⟩={cur_H:7.2f}   best Cut={best_cut:7.1f}\")\n",
        "\n",
        "            gc.collect()   # release unused tensors\n",
        "            torch.cuda.empty_cache()     # clear cached GPU memory\n",
        "        return hist, best_cut     # return training curve & best value\n",
        "\n",
        "\n",
        "    # Run training\n",
        "    A_np = parse_mc(file_name)    # load adjacency as dense NumPy array\n",
        "    A = to_sparse(A_np)    # convert to sparse PyTorch tensor\n",
        "\n",
        "    print(f\"Graph {file_name}: n = {A.shape[0]}, |E| = {A.indices().shape[1]}\")  # report size\n",
        "\n",
        "    hist, best_cut = train(A)      # start training with default params\n",
        "\n",
        "    print(f\"\\nFinal best Cutsize on {file_name}: {best_cut:.1f}\")  # final result\n",
        "\n",
        "    # Titles\n",
        "    title_str = (\n",
        "        f\"{file_name}  |  \"\n",
        "        f\"bestCut={best_cut:.1f}  |  \"\n",
        "        f\"tries={tries_value}, \"\n",
        "        f\"T={T_value}, steps={steps_value}, \"\n",
        "        f\"epochs={epochs_value}, batch={batch_value}, traj={traj_value}, \"\n",
        "        f\"lr={lr_value}, flips_ratio={flips_ratio_value}\"\n",
        "    )\n",
        "\n",
        "    # Plot mean H vs epoch\n",
        "    plt.figure(figsize=(10, 5), dpi=100)\n",
        "    plt.plot(hist)\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"mean H\")\n",
        "    plt.title(title_str)\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StCO-4TnBuc7"
      },
      "source": [
        "#♻ Garbage collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A431_x8RB8-o"
      },
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG9o7VSLZDRM"
      },
      "source": [
        "#**4. Benchmark against Metropolis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V57r46UMdVHQ"
      },
      "source": [
        "**HOW THE METROPOLIS ALGORITHM WORKS:**\n",
        "* This is the Metropolis algorithm for the antiferromagnetic Ising spin glass model.\n",
        "* It simulates graph lattice of $n$ nodes connected with edges, where each node has a spin $\\pm 1$.\n",
        "* The spins are initialized randomly.\n",
        "* The Hamiltonian is computed by summing spin interactions between nearest neighbors.\n",
        "* The $Cutsize$ function counts how many neighboring spins are opposite, which is the target configuration minimizing the Hamiltonian in antiferromagnetic materials.\n",
        "* The algorithm selects a site at random and calculates the energy change if we were to flip it. If flipping lowers the energy, the spin is flipped.\n",
        "If flipping increases energy, the spin is flipped with Boltzmann probability $p = e^{\\Delta E / k_B T}$. The higher the temperature $T$, the more the exploration.\n",
        "* The process is repeated for multiple iterations to reach thermal equilibrium at the given temperature $T$. At low temperatures $T ⟶ 0$, the configuration that opposes connected spins the most is favored.\n",
        "At high temperatures $T ⟶ ∞$, spins are randomly oriented due to thermal fluctuations. Indeed, $T$ is the standard deviation of the thermal energy distribution.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KojCUuRp2_HY"
      },
      "source": [
        "##**Metropolis implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHqH7kAzUHBe"
      },
      "source": [
        "* The main implementation in Section 3. uses helper functions that are adapted to Torch tensors.\n",
        "* Here, for benchmarking against Metropolis, we **rewrote some of the helper functions** so that they handle NumPy arrays instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UfjfqqY6yNt"
      },
      "outputs": [],
      "source": [
        "# Read .mc graph into dense NumPy adjacency\n",
        "def parse_mc(fname):\n",
        "    with open(fname) as f:\n",
        "        n, _ = map(int, f.readline().split())   # first line: nbr of nodes, dummy value\n",
        "        A = np.zeros((n, n), dtype=np.float32)    # allocate n*n zeros matrix\n",
        "        for line in f:        # remaining lines: u v w\n",
        "            u, v, w = map(int, line.split())\n",
        "            A[u - 1, v - 1] = w      # 1‑indexed file so 0‑indexed Python\n",
        "            A[v - 1, u - 1] = w      # undirected graph then symmetric\n",
        "    return A\n",
        "\n",
        "# random initialization of spins\n",
        "def rnd_spins(n):\n",
        "    return np.random.choice([-1, 1], n)\n",
        "\n",
        "\n",
        "# hamiltonian for numpy arrays\n",
        "def H(s, A):\n",
        "    s = np.asarray(s)\n",
        "    return 0.5 * (s @ A.dot(s) if sp.issparse(A) else np.sum(A * np.outer(s, s)))\n",
        "\n",
        "\n",
        "def cut(s, A):\n",
        "    s = np.asarray(s)\n",
        "    if sp.issparse(A):\n",
        "        return 0.25 * A.multiply(1 - np.outer(s, s)).sum()      # 1/2 * 1/2 to avoid overcount\n",
        "    return 0.25 * np.sum(A * (1 - np.outer(s, s)))\n",
        "\n",
        "\n",
        "# Metropolis algo\n",
        "def metro(s, A, T, steps=1_000):\n",
        "    s = np.asarray(s)\n",
        "    n = len(s)\n",
        "    sparse = sp.issparse(A)\n",
        "    for _ in range(steps):\n",
        "        i = np.random.randint(n)\n",
        "        dE = -2*s[i]*(A.getrow(i).toarray().dot(s).item() if sparse else A[i] @ s)\n",
        "        if dE <= 0 or np.random.rand() < np.exp(-dE/T):\n",
        "            s[i] *= -1    # flip spin\n",
        "    return s\n",
        "\n",
        "\n",
        "def plot_line(s, ttl):\n",
        "    plt.figure(figsize=(8,2))\n",
        "    plt.imshow(s[np.newaxis,:], cmap='coolwarm', vmin=-1, vmax=1, aspect='auto')\n",
        "    plt.title(ttl); plt.xticks([]); plt.yticks([]); plt.tight_layout(); plt.show()\n",
        "\n",
        "\n",
        "# visual samples: graphs with colored nodes\n",
        "def plot_net(A, s, ttl):\n",
        "    G = nx.from_scipy_sparse_array(sp.csr_matrix(A))\n",
        "    pos = nx.spring_layout(G, seed=1)\n",
        "    nx.draw_networkx_nodes(G, pos, node_color=['red' if x==1 else 'blue' for x in s], node_size=50)\n",
        "    nx.draw_networkx_edges(G, pos, alpha=.3)\n",
        "    plt.title(ttl); plt.axis('off'); plt.show()\n",
        "\n",
        "\n",
        "def run_metro(A, T=0.0, sweeps=500, name=\"\", mode=\"line\", Ts=None):\n",
        "    n = A.shape[0]\n",
        "    if mode in (\"heat\",\"heatmap\"):\n",
        "        Ts = Ts or [T]\n",
        "        fig, ax = plt.subplots(1, len(Ts), figsize=(4*len(Ts),2))\n",
        "        ax = [ax] if len(Ts)==1 else ax\n",
        "        for a, t in zip(ax, Ts):\n",
        "            s = rnd_spins(n)    # initialize graph of spins\n",
        "            s = metro(s, A, t, sweeps*n)    # run Metropolis\n",
        "            a.imshow(s[np.newaxis,:], cmap='coolwarm', vmin=-1, vmax=1, aspect='auto')\n",
        "            a.set_title(f\"{name}  T={t}  H={H(s,A):.2f}  Cut={cut(s,A):.2f}\")\n",
        "            a.set_yticks([]); a.set_xlabel('idx')\n",
        "        plt.tight_layout(); plt.show()\n",
        "        return\n",
        "\n",
        "    # ONE temperature\n",
        "    s = rnd_spins(n)\n",
        "    s = metro(s, A, T, sweeps*n)\n",
        "    ttl = f\"{name}  T={T}  H={H(s,A):.2f}  Cut={cut(s,A):.2f}\"\n",
        "\n",
        "    if mode==\"graph\":\n",
        "        plot_net(A, s, ttl)\n",
        "    else:\n",
        "        plot_line(s, ttl)\n",
        "\n",
        "    return s, H(s, A), cut(s, A), T\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35WoDGvXz8yE"
      },
      "source": [
        "##**Results Optsicom**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_oVBynHa1Cu"
      },
      "outputs": [],
      "source": [
        "# optsicom graphs\n",
        "ids = [\"54100\",\"54200\",\"54300\",\"54400\",\"54500\",\n",
        "       \"54600\",\"54700\",\"54800\",\"54900\",\"541000\"]\n",
        "\n",
        "for gid in ids:\n",
        "    adj = parse_mc(f\"g{gid}.mc\")\n",
        "    run_metro(adj, T=0.0,          # ground state config\n",
        "                   sweeps=500, name=f\"G{gid}\",\n",
        "                   mode=\"heatmap\", Ts=[0.0])\n",
        "\n",
        "# some graphs for the video presentation\n",
        "for gid in ids[:2]:\n",
        "    adj = parse_mc(f\"g{gid}.mc\")\n",
        "    run_metro(adj, T=0.0, sweeps=500, name=f\"G{gid}\", mode=\"line\")\n",
        "    run_metro(adj, T=0.0, sweeps=500, name=f\"G{gid}\", mode=\"graph\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMZsN-D0PC95"
      },
      "source": [
        "##**Results Gset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvL6aspqkXtS"
      },
      "outputs": [],
      "source": [
        "ids = [14, 15, 22, 49, 50, 55, 70]\n",
        "\n",
        "for gid in ids:\n",
        "    A = parse_mc(f\"G{gid}.mc\")\n",
        "    run_metro(A, T=0.0, sweeps=600, name=f\"G{gid}\", mode=\"line\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fs70H6MHl-h"
      },
      "source": [
        "#**5. Benchmark against Pure greedy local search**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Juqi06p3e00o"
      },
      "source": [
        "##**Results Optsicom**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ORaN6xgHpDi"
      },
      "outputs": [],
      "source": [
        "#Table 1\n",
        "ids = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
        "\n",
        "# Read .mc graph into dense NumPy adjacency\n",
        "def parse_mc(fname):\n",
        "    with open(fname) as f:\n",
        "        n, _ = map(int, f.readline().split())   # first line: nbr of nodes, dummy value\n",
        "        A = np.zeros((n, n), dtype=np.float32)    # allocate n*n zeros matrix\n",
        "        for line in f:        # remaining lines: u v w\n",
        "            u, v, w = map(int, line.split())\n",
        "            A[u - 1, v - 1] = w      # 1‑indexed file so 0‑indexed Python\n",
        "            A[v - 1, u - 1] = w      # undirected graph then symmetric\n",
        "    return A\n",
        "\n",
        "# Convert dense NumPy adjacency to sparse PyTorch tensor on GPU\n",
        "def to_sparse(adj):\n",
        "    sparse_mtx = scipy.sparse.coo_matrix(adj)     # build SciPy sparse matrix\n",
        "    idx = torch.tensor([sparse_mtx.row, sparse_mtx.col], device=device)   # edge indices as 2*|E| tensor\n",
        "    val = torch.tensor(sparse_mtx.data, dtype=torch.float32, device=device)  # edge weights\n",
        "    return torch.sparse_coo_tensor(idx, val, sparse_mtx.shape).coalesce()    # create & coalesce sparse tensor\n",
        "\n",
        "# Compute Max‑Cut value = 1/4 sum of A_ij(1−sigma_i*sigma_j) for a batch\n",
        "@torch.no_grad()\n",
        "def cutsize(spins, A):\n",
        "    if spins.dim() == 1:\n",
        "        spins = spins.unsqueeze(0)\n",
        "    A = A.coalesce()\n",
        "    idx, val = A.indices(), A.values()\n",
        "    prod = (1.0 - spins[:, idx[0]] * spins[:, idx[1]]) * val    # (1−sigma_i*sigma_j) * w_ij\n",
        "    return 0.25 * prod.sum(dim=1)\n",
        "\n",
        "def greedy(ids):\n",
        "    for g in ids:\n",
        "        # dense np array --> sparse tensor\n",
        "        A_np = parse_mc(f\"g54{g}.mc\")\n",
        "        A    = to_sparse(A_np)\n",
        "        n    = A.shape[0]\n",
        "        # count undirected edges\n",
        "        E = A.coalesce().indices().shape[1] // 2\n",
        "\n",
        "        print(f\"\\ng54{g}: n={n}, |E|={E}\")\n",
        "\n",
        "        # start all +1 spins\n",
        "        state     = torch.ones((1, n), device=device)\n",
        "        best_cut  = cutsize(state, A).item()\n",
        "\n",
        "        for t in range(E):\n",
        "            improved = False\n",
        "            # try flipping each spin\n",
        "            for i in range(n):\n",
        "                cand = state.clone()\n",
        "                cand[0, i] *= -1\n",
        "                c = cutsize(cand, A).item()\n",
        "                if c > best_cut:\n",
        "                    best_cut, state = c, cand\n",
        "                    improved = True\n",
        "            if not improved:\n",
        "                print(f\"  stopped after {t} iters\")\n",
        "                break\n",
        "\n",
        "        print(f\"  greedy g54{g} bestCut={best_cut:.1f}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    greedy(ids)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjKncG-5e4uq"
      },
      "source": [
        "##**Results Gset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSeW5aAgv1nk"
      },
      "outputs": [],
      "source": [
        "# Table 2\n",
        "ids = [14, 15, 22, 49, 50, 55, 70]\n",
        "\n",
        "# Read .mc graph into dense NumPy adjacency\n",
        "def parse_mc(fname):\n",
        "    with open(fname) as f:\n",
        "        n, _ = map(int, f.readline().split())   # first line: nbr of nodes, dummy value\n",
        "        A = np.zeros((n, n), dtype=np.float32)    # allocate n*n zeros matrix\n",
        "        for line in f:        # remaining lines: u v w\n",
        "            u, v, w = map(int, line.split())\n",
        "            A[u - 1, v - 1] = w      # 1‑indexed file so 0‑indexed Python\n",
        "            A[v - 1, u - 1] = w      # undirected graph then symmetric\n",
        "    return A\n",
        "\n",
        "# Convert dense NumPy adjacency to sparse PyTorch tensor on GPU\n",
        "def to_sparse(adj):\n",
        "    sparse_mtx = scipy.sparse.coo_matrix(adj)     # build SciPy sparse matrix\n",
        "    idx = torch.tensor([sparse_mtx.row, sparse_mtx.col], device=device)   # edge indices as 2*|E| tensor\n",
        "    val = torch.tensor(sparse_mtx.data, dtype=torch.float32, device=device)  # edge weights\n",
        "    return torch.sparse_coo_tensor(idx, val, sparse_mtx.shape).coalesce()    # create & coalesce sparse tensor\n",
        "\n",
        "# Compute Max‑Cut value = 1/4 sum of A_ij(1−sigma_i*sigma_j) for a batch\n",
        "@torch.no_grad()\n",
        "def cutsize(spins, A):\n",
        "    if spins.dim() == 1:\n",
        "        spins = spins.unsqueeze(0)\n",
        "    A = A.coalesce()\n",
        "    idx, val = A.indices(), A.values()\n",
        "    prod = (1.0 - spins[:, idx[0]] * spins[:, idx[1]]) * val    # (1−sigma_i*sigma_j) * w_ij\n",
        "    return 0.25 * prod.sum(dim=1)\n",
        "\n",
        "def greedy(ids):\n",
        "    for g in ids:\n",
        "        # dense np array --> sparse tensor\n",
        "        A_np = parse_mc(f\"G{g}.mc\")\n",
        "        A    = to_sparse(A_np)\n",
        "        n    = A.shape[0]\n",
        "        # count undirected edges\n",
        "        E = A.coalesce().indices().shape[1] // 2\n",
        "\n",
        "        print(f\"\\nG{g}: n={n}, |E|={E}\")\n",
        "\n",
        "        # start all +1 spins\n",
        "        state     = torch.ones((1, n), device=device)\n",
        "        best_cut  = cutsize(state, A).item()\n",
        "\n",
        "        for t in range(E):\n",
        "            improved = False\n",
        "            # try flipping each spin\n",
        "            for i in range(n):\n",
        "                cand = state.clone()\n",
        "                cand[0, i] *= -1\n",
        "                c = cutsize(cand, A).item()\n",
        "                if c > best_cut:\n",
        "                    best_cut, state = c, cand\n",
        "                    improved = True\n",
        "            if not improved:\n",
        "                print(f\"  stopped after {t} iters\")\n",
        "                break\n",
        "\n",
        "        print(f\"  greedy G{g} bestCut={best_cut:.1f}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    greedy(ids)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "CqDVXFTilQhT",
        "0WFyYkj1-kVY",
        "lTMvPFp5jLUw",
        "VnIPdjy7z622",
        "Jxm8bVF_CJDf",
        "StCO-4TnBuc7",
        "uG9o7VSLZDRM",
        "KojCUuRp2_HY",
        "35WoDGvXz8yE",
        "pMZsN-D0PC95",
        "1fs70H6MHl-h",
        "Juqi06p3e00o",
        "CjKncG-5e4uq"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
